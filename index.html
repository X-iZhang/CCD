<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
      content="CCD is a novel approach to mitigate hallucinations in radiology multimodal large language models (MLLMs) through Clinical Contrastive Decoding, enhancing the accuracy and reliability of AI-generated radiology reports.">
  <meta name="keywords" content="CCD, AI radiology, temporal medical imaging, chest X-rays, multimodal LLMs, radiology report generation, deep learning, medical AI, biomedical NLP, temporal analysis, MIMIC-CXR, RadDINO, Meditron, Xi Zhang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CCD</title>
  <!-- Open Graph Meta Tags -->
  <meta property="og:title" content="CCD: Mitigating Hallucinations in Radiology MLLMs via Clinical Contrastive Decoding">
  <meta property="og:description" content="CCD is a novel approach to mitigate hallucinations in radiology multimodal large language models (MLLMs) through Clinical Contrastive Decoding, enhancing the accuracy and reliability of AI-generated radiology reports.">
  <meta property="og:image" content="https://github.com/X-iZhang/CCD/blob/main/assets/CCD_icon_logo.png">
  <meta property="og:url" content="https://x-izhang.github.io/CCD/">
  <meta property="og:type" content="website">
  
  <!-- Twitter Card (for better previews on Twitter) -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="CCD: Mitigating Hallucinations in Radiology MLLMs via Clinical Contrastive Decoding">
  <meta name="twitter:description" content="CCD is a novel approach to mitigate hallucinations in radiology multimodal large language models (MLLMs) through Clinical Contrastive Decoding, enhancing the accuracy and reliability of AI-generated radiology reports.">
  <meta name="twitter:image" content="https://github.com/X-iZhang/CCD/blob/main/assets/CCD_icon_logo.png">

  <!-- Favicon (for browser tabs and bookmarks) -->
  <link rel="icon" type="image/x-icon" href="static/images/CCD_icon.png">
  
  <meta name="google-site-verification" content="6lbYN1vX7A4sD8SrVniq84UEKyEUSBgxeP7d3FjuuK0" />

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script type="module" src="https://gradio.s3-us-west-2.amazonaws.com/5.9.1/gradio.js"></script>
</head>

<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title"><img src="static/images/CCD_icon_logo.png"
            style="height: 50px; margin-right: 10px; vertical-align: text-top;">CCD: Mitigating Hallucinations in Radiology MLLMs via <br><u>C</u>linical <u>C</u>ontrastive <u>D</u>ecoding</h1>
          
          <!-- Paper authors -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">
                <a href="https://x-izhang.github.io/">Xi Zhang</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="https://mengzaiqiao.github.io/">Zaiqiao Meng</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="https://jakelever.github.io/">Jake Lever</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.edho.net/">Edmond S. L. Ho</a>,
            </span>
          </div>

          <br>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup><a href="https://www.gla.ac.uk/schools/computing/research/researchsections/ida-section/informationretrieval/">1</a></sup>Information Retrieval Group</span><br>
            <span class="author-block"><sup><a href="https://ai4biomed.org/">2</a></sup>AI4BioMed Lab</span><br>
            <span class="author-block"><b style="color:#A9A9A9; font-weight:normal">&#x25B6 </b>School of Computing Science, University of Glasgow, UK</span>
          </div>

          <br>
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Arxiv PDF link -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/0000" target="_blank"
                   class="external-link button is-normal is-rounded is-danger">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <!-- Github link -->
              <span class="link-block">
                <a href="https://github.com/X-iZhang/CCD" target="_blank" 
                    class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              
              <span class="link-block">
                <a href="https://huggingface.co/spaces/X-iZhang/CCD" target="_blank"
                   class="external-link button is-normal is-rounded is-link">
                <span class="icon">
                  <i class="far fa-images"></i>
                </span>
                <span>Demo</span>
              </a>
              </span>

              <span class="link-block">
                <a href="https://huggingface.co/collections/X-iZhang/ccd-68b9f5db2f03525b465ee09c" target="_blank"
                  class="external-link button is-normal is-rounded is-warning">
                  <span class="icon">
                    <i class="fas fa-database"></i>
                  </span>
                  <span>Datasets</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://huggingface.co/collections/X-iZhang/libra-6772bfccc6079298a0fa5f8d" target="_blank"
                  class="external-link button is-normal is-rounded is-primary">
                  <span class="icon">
                    <i class="fas fa-share-square"></i>
                  </span>
                  <span>Models</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero">
  <div class="container is-max-widescreen">
    <div class="hero-body">
      <h4 class="subtitle has-text-centered"></h4>
      üî•<strong><span style="color: #ff3860">[NEWS!]</span></strong> 
        <div class="news-item">
          <strong>[27 Sep 2025]</strong> ‚õ≥ Our preprint is now live on <a href="https://arxiv.org/abs/0">arXiv</a> ‚Äî check it out for details.
        </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Multimodal large language models (MLLMs) have recently achieved remarkable progress in radiology by integrating visual perception with natural language understanding. However, they often generate clinically unsupported descriptions, known as medical hallucinations, which pose serious risks in medical applications that demand accuracy and image-grounded outputs. Through empirical analysis, we find that prompt-induced hallucinations remain prevalent in radiology MLLMs, largely due to over-sensitivity to clinical sections. To address this, we introduce <strong><u>C</u></strong>linical <strong><u>C</u></strong>ontrastive <strong><u>D</u></strong>ecoding (<strong>CCD</strong>), a training-free and retrieval-free inference framework that integrates structured clinical signals from task‚Äëspecific radiology expert models. CCD introduces a dual-stage contrastive mechanism to refine token-level logits during generation, thereby enhancing clinical fidelity without modifying the base MLLM. Experiments on three datasets and multiple models demonstrate that CCD consistently improves overall performance on radiology report generation (RRG). On the MIMIC-CXR dataset, it yields up to a <strong>17%</strong> improvement in RadGraph-F1 when applied to state-of-the-art RRG models. Our approach provides a lightweight and generalisable solution for mitigating medical hallucinations, effectively bridging expert models and MLLMs in radiology.
          </p>
          <img src="static/images/CCD_framework_new.png">
        </div>
      </div>
    </div>

  </div>
</section>

<!-- <iframe
  src="https://huggingface.co/datasets/X-iZhang/MIMIC-CXR-RRG/embed/viewer/findings_section/test"
  frameborder="0"
  width="50%"
  height="560px"
></iframe> -->

<!-- <section class="section hero is-light" id="OnlineDemo">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Demo</h2>
    <div class="content has-text-centered">
      <p>Explore the capabilities of CCD with our interactive demo.</p>
      <gradio-app src="https://x-izhang-libra.hf.space"></gradio-app>
    </div>
  </div>
</section> -->

<section class="hero teaser" style="
  margin: 3em auto; 
  font-style: italic; 
  font-size: 1.3em; 
  font-family: 'Georgia', serif;
  max-width: 720px; 
  padding: 0 1em;
">
  <p style="margin-bottom: 1.5em;">
    ‚ÄúIt‚Äôs better to be roughly right than precisely wrong.‚Äù
  </p>
  <div style="text-align: right;">
    ‚Äî <strong>Carveth Read</strong><br>
    <em>Logic: Deductive and Inductive</em>
  </div>
</section>


<!-- Why CCD -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Ê†áÈ¢òÂ±Ö‰∏≠ -->
    <div class="has-text-centered" style="margin-bottom: 20px;">
      <h2 class="title is-3 has-text-centered">Why CCD?</h2>
    </div>
    <div class="columns is-centered">
      <!-- Â∑¶‰æßÔºöÊèíÂÖ•ÂõæÂÉè -->
      <div class="content has-text-justified">
        <img src="static/images/hallucination_cases_large_size.png" alt="Clinical hallucination cases mitigated by CCD" style="max-width: 100%; height: auto;">
      </div>
    </div>
    <div class="content has-text-justified" style="margin-top: 1.5rem;">
      <p>
        Radiology MLLMs remain vulnerable to <em>prompt-induced hallucinations</em> when clinical sections contain counterfactual details or ambiguous guidance. The figure above contrasts baseline predictions with CCD-enabled outputs across report generation and question answering tasks. <strong><span style="color: #ff3860">Red</span></strong>  highlights mark unsupported findings that can compromise patient care, while <strong><span style="color: #018afb;">blue</span></strong> text reflects misleading prompt context the model must resist.
      </p>
      <p>
        <strong>Clinical Contrastive Decoding</strong> mitigates these risks at inference time. Rather than retraining models or relying on retrieval corpora, CCD injects trustworthy, image-grounded signals distilled from specialist expert models. The result is a decoding policy that maintains fluency yet stays faithful to the radiograph.
      </p>
    </div>
  </div>
</section>

<section class="section">
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">Overview</h2>
      <div class="content has-text-justified">
        <p>
          <strong>Clinical Contrastive Decoding (CCD)</strong> is a plug-and-play inference framework designed to reduce medical hallucinations in radiology MLLMs. It introduces structured clinical supervision from expert models (e.g., DenseNet or MedSigLIP) at decoding time, without modifying model weights or requiring external retrieval.
        </p>
        <p>
          Given a chest radiograph, the expert model predicts symptom-level probabilities across 14 CheXpert categories. CCD integrates this signal through a dual-stage logit refinement strategy:
        </p>
        <ul>
          <li>
            <strong>Symptom-grounded Contrastive Decoding (SCD):</strong> constructs an anchor prompt using high-confidence findings (e.g., ‚ÄúAtelectasis, Cardiomegaly‚Äù) and generates a contrastive logits path conditioned on this prompt. The final logits are a weighted interpolation between the anchor-conditioned and original paths, encouraging the model to mention supported findings and suppress false negatives.
          </li>
          <li>
            <strong>Expert-informed Contrastive Decoding (ECD):</strong> transforms expert probabilities into token-level logit biases via log-odds conversion. These biases are injected into the logits from the first stage, softly penalising unsupported findings and reducing false positives.
          </li>
        </ul>
        <p>
          This two-stage mechanism enables CCD to progressively guide generation with both symbolic supervision (via anchor prompts) and probabilistic constraints (via confidence scores), achieving robust improvements in both report generation and VQA. CCD is fully model-agnostic and integrates seamlessly with state-of-the-art radiology MLLMs such as <em>MAIRA-2</em>, <em>Libra</em>, <em>LLaVA-Rad</em>, and <em>LLaVA-Med</em>.
        </p>
        <p>
        Unlike prior contrastive decoding approaches that rely on perturbed visual or textual inputs, <strong>CCD</strong> leverages clinically grounded signals from expert models to provide task-specific and symptom-level control during generation.
        </p>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">Key Contributions</h2>
      <div class="content has-text-justified">
        <ul>
          <li><b style="color: #FF6347;">Empirical Insight:</b> We systematically analyse prompt-induced hallucinations in radiology MLLMs and demonstrate that noisy clinical sections‚Äîsuch as irrelevant or contradictory prompts‚Äîcan trigger unsupported findings across multiple datasets.</li>
          <li><b style="color: #4682B4;">Inference-time Framework:</b> We propose <strong>Clinical Contrastive Decoding (CCD)</strong>, a dual-stage inference strategy that incorporates expert-derived labels as anchor prompts and probabilistic logits adjustments. CCD requires no retraining, architectural changes, or external retrieval modules.</li>
          <li><b style="color: #32CD32;">Consistent Gains:</b> Extensive experiments on <em>MIMIC-CXR</em>, <em>IU-Xray</em>, and <em>CheXpert Plus</em> show that CCD improves RadGraph-F1 by up to <strong>+17%</strong> and enhances VQA accuracy‚Äîall without modifying model weights or architecture.</li>
        </ul>
      </div>
    </div>
  </div>
</section>

<!-- Empirical Analyses -->
<section class="section">
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">Empirical Analyses</h2>
      <div class="content has-text-justified">

        <p>
          To understand how hallucinations arise in radiology MLLMs, we conduct a systematic study on the <strong>MIMIC-CXR</strong> dataset, evaluating how different clinical sections affect report generation. 
          The table below quantifies the impact of appending specific sections (e.g., <em>Indication</em>, <em>Technique</em>, <em>Comparison</em>) on both lexical and clinical metrics.
        </p>

        <div class="columns is-centered">
          <div class="column is-centered">
            <img src="static/images/table_1.png" alt="Medical Hallucination Analysis Table" style="display: block; margin: 0 auto; max-width: 100%;">
            <!-- <p class="has-text-centered is-size-7 has-text-grey">Table: Evaluation of prompt-induced hallucinations with different clinical sections. ‚Üì indicates performance degradation.</p> -->
          </div>
        </div>

        <p>
          <strong>Hallucination Drivers: Clinical Context Sensitivity.</strong> Our results show that appending different clinical sections leads to inconsistent‚Äîand sometimes harmful‚Äîeffects on generation. For example, adding <em>History</em> or <em>Technique</em> can slightly improve fluency due to stylistic overlap with report narratives. However, <em>Comparison</em> consistently harms performance across all metrics (e.g., BERTScore ‚Üì 8.12), as it often references prior images or temporal changes that are absent in the current input. This mismatch between prompt and image causes the model to hallucinate unsupported findings.
        </p>

        <p>
          Clinically, we observe that the inclusion of misleading or overly strong prompts can cause the model to overlook subtle image features (e.g., Pleural Effusion, Atelectasis), leading to both over-diagnosis and under-detection. These findings highlight the limitations of na√Øvely using full report context as generation input.
        </p>

        <p>
          <strong>Motivation for CCD:</strong> These empirical observations motivate the need for a decoding-time solution that selectively integrates structured, image-grounded signals‚Äîrather than relying on potentially noisy clinical text prompts. Our proposed <strong>CCD</strong> framework addresses this by incorporating expert-derived labels and probabilities to guide generation in a controlled and clinically consistent manner.
        </p>

      </div>
    </div>
  </div>
</section>

<!-- Experimental Results -->
<section class="section hero is-light">
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">Experimental Results on RRG</h2>
      <div class="content has-text-justified">
        <div class="columns is-centered">
          <div class="column is-centered">
            <img src="static/images/table_2.png" style="display: block; margin: 0 auto;">
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Experimental Results -->
<section class="section hero">
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">Additional Experimental Results on RRG</h2>
      <div class="content has-text-justified">
        <div class="columns is-centered">
          <div class="column is-centered">
            <img src="static/images/table_6.png" style="display: block; margin: 0 auto;">
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Experimental Results -->
<section class="section hero is-light">
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">Experimental Results on VQA</h2>
      <div class="content has-text-justified">
        <div class="columns is-centered">
          <div class="column is-centered">
            <img src="static/images/table_3.png" style="display: block; margin: 0 auto;">
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- ABLATION STUDIES -->
<section class="section hero">
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">Ablation Studies</h2>
      <div class="content has-text-justified">
        <div class="columns is-centered">
          <div class="column is-centered">
            <img src="static/images/table_4.png" style="display: block; margin: 0 auto;">
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{zhang2026ccd,
  title={CCD: Mitigating Hallucinations in Radiology MLLMs via Clinical Contrastive Decoding},
  author={Zhang, Xi and Meng, Zaiqiao and Lever, Jake and Ho, Edmond S. L.},
  booktitle=tbd,
  year={2025},
  url={https://x-izhang.github.io/CCD/}
}
</code></pre>
  </div>
</section>
<section class="section" id="Acknowledgement">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgement</h2>
    <p>
      This website is adapted from <a
      href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, licensed under a <a rel="license"
                                          href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
      Commons Attribution-ShareAlike 4.0 International License</a>.
    </p>
  </div>
</section>

</body>

</html>
