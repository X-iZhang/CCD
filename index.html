<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
      content="CCD is a novel approach to mitigate hallucinations in radiology multimodal large language models (MLLMs) through Clinical Contrastive Decoding, enhancing the accuracy and reliability of AI-generated radiology reports.">
  <meta name="keywords" content="CCD, AI radiology, temporal medical imaging, chest X-rays, multimodal LLMs, radiology report generation, deep learning, medical AI, biomedical NLP, temporal analysis, MIMIC-CXR, RadDINO, Meditron, Xi Zhang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CCD</title>
  <!-- Open Graph Meta Tags -->
  <meta property="og:title" content="CCD: Mitigating Hallucinations in Radiology MLLMs via Clinical Contrastive Decoding">
  <meta property="og:description" content="CCD is a novel approach to mitigate hallucinations in radiology multimodal large language models (MLLMs) through Clinical Contrastive Decoding, enhancing the accuracy and reliability of AI-generated radiology reports.">
  <meta property="og:image" content="https://github.com/X-iZhang/CCD/blob/main/assets/CCD_icon_logo.png">
  <meta property="og:url" content="https://x-izhang.github.io/CCD/">
  <meta property="og:type" content="website">
  
  <!-- Twitter Card (for better previews on Twitter) -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="CCD: Mitigating Hallucinations in Radiology MLLMs via Clinical Contrastive Decoding">
  <meta name="twitter:description" content="CCD is a novel approach to mitigate hallucinations in radiology multimodal large language models (MLLMs) through Clinical Contrastive Decoding, enhancing the accuracy and reliability of AI-generated radiology reports.">
  <meta name="twitter:image" content="https://github.com/X-iZhang/CCD/blob/main/assets/CCD_icon_logo.png">

  <!-- Favicon (for browser tabs and bookmarks) -->
  <link rel="icon" type="image/x-icon" href="static/images/CCD_icon.png">
  
  <meta name="google-site-verification" content="6lbYN1vX7A4sD8SrVniq84UEKyEUSBgxeP7d3FjuuK0" />

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script type="module" src="https://gradio.s3-us-west-2.amazonaws.com/5.9.1/gradio.js"></script>
</head>

<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title"><img src="static/images/CCD_icon_logo.png"
            style="height: 50px; margin-right: 10px; vertical-align: text-top;">CCD: Mitigating Hallucinations in Radiology MLLMs via <br><u>C</u>linical <u>C</u>ontrastive <u>D</u>ecoding</h1>
          
          <!-- Paper authors -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">
                <a href="https://x-izhang.github.io/">Xi Zhang</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="https://mengzaiqiao.github.io/">Zaiqiao Meng</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="https://jakelever.github.io/">Jake Lever</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.edho.net/">Edmond S. L. Ho</a>,
            </span>
          </div>

          <br>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup><a href="https://www.gla.ac.uk/schools/computing/research/researchsections/ida-section/informationretrieval/">1</a></sup>Information Retrieval Group</span><br>
            <span class="author-block"><sup><a href="https://ai4biomed.org/">2</a></sup>AI4BioMed Lab</span><br>
            <span class="author-block"><b style="color:#A9A9A9; font-weight:normal">&#x25B6 </b>School of Computing Science, University of Glasgow, UK</span>
          </div>

          <br>
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Arxiv PDF link -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/0000" target="_blank"
                   class="external-link button is-normal is-rounded is-danger">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <!-- Github link -->
              <span class="link-block">
                <a href="https://github.com/X-iZhang/CCD" target="_blank" 
                    class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              
              <span class="link-block">
                      <a href="https://huggingface.co/collections/X-iZhang/ccd-68b9f5db2f03525b465ee09c" target="_blank"
                         class="external-link button is-normal is-rounded is-light">
                      <span class="icon">
                        ü§ó
                      </span>
                      <span>Space</span>
                    </a>
              </span>

              <span class="link-block">
                <a href="https://github.com/X-iZhang/CCD" target="_blank"
                  class="external-link button is-normal is-rounded is-warning">
                  <span class="icon">
                    <i class="fas fa-database"></i>
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://huggingface.co/collections/X-iZhang/libra-6772bfccc6079298a0fa5f8d" target="_blank"
                  class="external-link button is-normal is-rounded is-primary">
                  <span class="icon">
                    <i class="fas fa-share-square"></i>
                  </span>
                  <span>Model</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-widescreen">
    <div class="hero-body">
      <h4 class="subtitle has-text-centered"></h4>
      üî•<strong><span style="color: #ff3860">[NEWS!]</span></strong> 

      <div class="news-item">
        ü§ñ We're still cooking ‚Äî Stay tuned! ü§ñ
        <br>
        ‚≠ê Give us a star if you like it! ‚≠ê
      </div>

      <!-- <div class="video-grid">
        <div class="video-container" style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; border-radius: 16px;">
          <iframe
            src="https://www.youtube.com/embed/_R8XUaaAU3g"
            title="Demo Video"
            frameborder="0"
            allow="autoplay; encrypted-media; fullscreen"
            allowfullscreen
            style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border-radius: 16px;">
          </iframe>
        </div>
      </div> -->

    </div>
  </div>
</section>

<section class="hero teaser" style="
  margin: 3em auto; 
  font-style: italic; 
  font-size: 1.3em; 
  font-family: 'Georgia', serif;
  max-width: 720px; 
  padding: 0 1em;
">
  <p style="margin-bottom: 1.5em;">
    ‚ÄúIt‚Äôs better to be roughly right than precisely wrong.‚Äù
  </p>
  <div style="text-align: right;">
    ‚Äî <strong>Carveth Read</strong><br>
    <em>Logic: Deductive and Inductive</em>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Multimodal large language models (MLLMs) have recently achieved remarkable progress in radiology by integrating visual perception with natural language understanding. However, they often generate clinically unsupported descriptions, known as medical hallucinations, which pose serious risks in medical applications that demand accuracy and image-grounded outputs. Through empirical analysis, we find that prompt-induced hallucinations remain prevalent in radiology MLLMs, largely due to over-sensitivity to clinical sections. To address this, we introduce <strong><u>C</u></strong>linical <strong><u>C</u></strong>ontrastive <strong><u>D</u></strong>ecoding (<strong>CCD</strong>), a training-free and retrieval-free inference framework that integrates structured clinical signals from task‚Äëspecific radiology expert models. CCD introduces a dual-stage contrastive mechanism to refine token-level logits during generation, thereby enhancing clinical fidelity without modifying the base MLLM. Experiments on three datasets and multiple models demonstrate that CCD consistently improves overall performance on radiology report generation (RRG). On the MIMIC-CXR dataset, it yields up to a <strong>17%</strong> improvement in RadGraph-F1 when applied to state-of-the-art RRG models. Our approach provides a lightweight and generalisable solution for mitigating medical hallucinations, effectively bridging expert models and MLLMs in radiology.
          </p>
          <img src="static/images/CCD_framework_new.png">
        </div>
      </div>
    </div>

  </div>
</section>

<!-- <iframe
  src="https://huggingface.co/datasets/X-iZhang/MIMIC-CXR-RRG/embed/viewer/findings_section/test"
  frameborder="0"
  width="50%"
  height="560px"
></iframe> -->

<!-- <section class="section" id="OnlineDemo">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Demo</h2>
    <div class="content has-text-centered">
      <p>Explore the capabilities of Libra with our interactive demo.</p>
      <gradio-app src="https://x-izhang-libra.hf.space"></gradio-app>
    </div>
  </div>
</section> -->

<!-- Why CCD -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Ê†áÈ¢òÂ±Ö‰∏≠ -->
    <div class="has-text-centered" style="margin-bottom: 20px;">
      <h2 class="title is-3 has-text-centered">Why CCD?</h2>
    </div>
    <div class="columns is-centered">
      <!-- Â∑¶‰æßÔºöÊèíÂÖ•ÂõæÂÉè -->
      <div class="content has-text-justified">
        <img src="static/images/hallucination_cases_large_size.png" alt="Temporal Awareness in Report Generation" style="max-width: 100%; height: auto;">
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">Overview</h2>
      <div class="content has-text-justified">
        <p>
          We propose <strong>Libra</strong> (<strong>L</strong>everaging Temporal <strong>I</strong>mages for <strong>B</strong>iomedical <strong>R</strong>adiology <strong>A</strong>nalysis), a novel framework tailored for radiology report generation (RRG) that incorporates temporal change information to address the challenges of interpreting medical images effectively.
        </p>
        <p>
          Libra leverages RAD-DINO, a pre-trained visual transformer, as its image encoder to generate robust and scalable image features. These features are further refined by a <strong>Temporal Alignment Connector (TAC)</strong>, a key innovation in Libra's architecture. The TAC comprises:
        </p>
        <ul>
          <li><strong>Layerwise Feature Extractor (LFE):</strong> Captures high-granularity image feature embeddings from the encoder.</li>
          <li><strong>Temporal Fusion Module (TFM):</strong> Integrates temporal references from prior studies to enhance temporal awareness and reasoning.</li>
        </ul>
        <p>
          These refined features are fed into Meditron, a specialised medical large language model (LLM), to generate comprehensive, temporally-aware radiology reports. Libra‚Äôs modular design seamlessly integrates state-of-the-art open-source pre-trained models for both image and text, aligning them through a temporal-aware adapter to ensure robust cross-modal reasoning and understanding.
        </p>
        <p>
          Through a two-stage training strategy, Libra demonstrates the powerful potential of multimodal large language models (MLLMs) in specialised radiology applications. Extensive experiments on the <strong>MIMIC-CXR dataset</strong> highlight Libra's performance, setting a new state-of-the-art benchmark among models of the same parameter scale.
        </p>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">Key Contributions</h2>
      <div class="content has-text-justified">
        <ul>
          <li><b style="color: #FF6347;">Temporal Awareness:</b> Libra captures and synthesizes temporal changes in medical images, addressing the challenge of handling prior study citations in RRG tasks.</li>
          <li><b style="color: #4682B4;">Innovative Architecture:</b> The Temporal Alignment Connector (TAC) ensures high-granularity feature extraction and temporal integration, significantly enhancing cross-modal reasoning capabilities.</li>
          <li><b style="color: #32CD32;">State-of-the-Art Performance:</b> Libra achieves outstanding results on the MIMIC-CXR dataset, outperforming existing MLLMs in both accuracy and temporal reasoning.</li>
          <li><b style="color: #FFD700;">Libra Repository:</b> Our code space provides a public and detailed implementation of Libra, facilitating reproducibility and further research in the field, and integrates both training and evaluation processes, ensuring a streamlined and efficient workflow for developing and testing radiology report generation models.</li>
        </ul>
      </div>
    </div>
  </div>
</section>

<!-- Experimental Results -->
<section class="section">
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">Experimental Results</h2>
      <div class="content has-text-justified">
        <div class="columns is-centered">
          <div class="column is-centered">
            <img src="static/images/results.png" style="display: block; margin: 0 auto;">
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">Performance Analysis</h2>
      <div class="content has-text-justified">
        <div class="columns is-centered">
          <div class="column is-centered">
            <img src="static/images/figure_3.png" style="display: block; margin: 0 auto;">
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
@misc{zhang2025libraleveragingtemporalimages,
  title={Libra: Leveraging Temporal Images for Biomedical Radiology Analysis}, 
  author={Xi Zhang and Zaiqiao Meng and Jake Lever and Edmond S. L. Ho},
  year={2025},
  eprint={2411.19378},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2411.19378}, 
}
</code></pre>
  </div>
</section>
<section class="section" id="Acknowledgement">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgement</h2>
    <p>
      This website is adapted from <a
      href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, licensed under a <a rel="license"
                                          href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
      Commons Attribution-ShareAlike 4.0 International License</a>.
    </p>
  </div>
</section>

</body>

</html>
